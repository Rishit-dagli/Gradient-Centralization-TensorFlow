{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gctf-mnist.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWyHHzLgF82QtHcNePAgxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishit-dagli/Gradient-Centralization-TensorFlow/blob/main/example/gctf_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IieqPex4O3eJ"
      },
      "source": [
        "# GCTF MNIST\r\n",
        "\r\n",
        "This notebook shows the the process of using the [`gradient-centralization-tf`](https://github.com/Rishit-dagli/Gradient-Centralization-TensorFlow) Python package to train on the [Fashion MNIST](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist) dataset availaible from [`tf.keras.datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets).Gradient Centralization is a simple and effective optimization technique for Deep Neural Networks as suggested by Yong et al. in the paper \r\n",
        "[Gradient Centralization: A New Optimization Technique for Deep Neural Networks](https://arxiv.org/abs/2004.01461). It can both speedup training \r\n",
        " process and improve the final generalization performance of DNNs.\r\n",
        "\r\n",
        "## A bit about GC\r\n",
        "\r\n",
        "Gradient Centralization operates directly on gradients by centralizing the gradient vectors to have zero mean. It can both speedup training process and improve the final generalization performance of DNNs. Here is an Illustration of the GC operation on gradient matrix/tensor of weights in the fully-connected layer (left) and convolutional layer (right). GC computes the column/slice mean of gradient matrix/tensor and centralizes each column/slice to have zero mean.\r\n",
        "\r\n",
        "![](https://i.imgur.com/KitoO8J.png)\r\n",
        "\r\n",
        "GC can be viewed as a projected gradient descent method with a constrained loss function. The geometrical interpretation of GC. The gradient is projected on a hyperplane $e^T(w-w^t)=0$, where the projected gradient is used to update the weight.\r\n",
        "\r\n",
        "![](https://i.imgur.com/ekHhQv0.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcpkfjkwSjmv"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjTQqCEaTSSG"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from time import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32NuQrDdSpP3"
      },
      "source": [
        "### Install the package\r\n",
        "\r\n",
        "Will soon be replaced by `pip install`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFvPquvcOq1B",
        "outputId": "16e01b14-35a6-4568-e21e-4b3d878ac865"
      },
      "source": [
        "import os\r\n",
        "from getpass import getpass\r\n",
        "import urllib\r\n",
        "\r\n",
        "user = input('User name: ')\r\n",
        "password = getpass('Password: ')\r\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\r\n",
        "repo_name = input('Repo name: ')\r\n",
        "\r\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\r\n",
        "\r\n",
        "os.system(cmd_string)\r\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: Rishit-dagli\n",
            "Password: ··········\n",
            "Repo name: Gradient-Centralization-TensorFlow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw1LSr5AS373",
        "outputId": "f2727155-b73d-446e-bef9-709034f392af"
      },
      "source": [
        "%cd Gradient-Centralization-TensorFlow/\r\n",
        "\r\n",
        "#Install the package\r\n",
        "!pip install -e .\r\n",
        "import gctf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Gradient-Centralization-TensorFlow\n",
            "Obtaining file:///content/Gradient-Centralization-TensorFlow\n",
            "Requirement already satisfied: tensorflow~=2.4.0 in /usr/local/lib/python3.6/dist-packages (from gradient-centralization-tf==0.0.1) (2.4.1)\n",
            "Requirement already satisfied: keras~=2.4.0 in /usr/local/lib/python3.6/dist-packages (from gradient-centralization-tf==0.0.1) (2.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.32.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras~=2.4.0->gradient-centralization-tf==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras~=2.4.0->gradient-centralization-tf==0.0.1) (3.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (53.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.25.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (3.3.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (4.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow~=2.4.0->gradient-centralization-tf==0.0.1) (3.4.0)\n",
            "Installing collected packages: gradient-centralization-tf\n",
            "  Running setup.py develop for gradient-centralization-tf\n",
            "Successfully installed gradient-centralization-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okru2B3uTKRx"
      },
      "source": [
        "## Get the data and create model structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywUm1ZYiOY8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9fae9d-6592-47da-9ea9-10a554ce1f11"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\r\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\r\n",
        "training_images  = training_images / 255.0\r\n",
        "test_images = test_images / 255.0\r\n",
        "\r\n",
        "# Model architecture\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "                                    tf.keras.layers.Flatten(), \r\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\r\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\r\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\r\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu), \r\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p_jknUHUILI"
      },
      "source": [
        "## Train a model without `gctf`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Us9_ZCBpD2a"
      },
      "source": [
        "Make a Callback to compute computation time\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADdFS7OapCXZ"
      },
      "source": [
        "class TimeHistory(tf.keras.callbacks.Callback):\r\n",
        "    def on_train_begin(self, logs={}):\r\n",
        "        self.times = []\r\n",
        "\r\n",
        "    def on_epoch_begin(self, batch, logs={}):\r\n",
        "        self.epoch_time_start = time()\r\n",
        "\r\n",
        "    def on_epoch_end(self, batch, logs={}):\r\n",
        "        self.times.append(time() - self.epoch_time_start)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQXmGp4_Oj7l",
        "outputId": "1488a649-671c-4f0d-fb22-e6e66eaf1c3e"
      },
      "source": [
        "time_callback_no_gctf = TimeHistory()\r\n",
        "\r\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\r\n",
        "              loss = 'sparse_categorical_crossentropy',\r\n",
        "              metrics = ['accuracy'])\r\n",
        "\r\n",
        "history_no_gctf = model.fit(training_images, training_labels, epochs=5, callbacks = [time_callback_no_gctf])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 2ms/step - loss: 0.6577 - accuracy: 0.7620\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4020 - accuracy: 0.8530\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3619 - accuracy: 0.8700\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3298 - accuracy: 0.8808\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3122 - accuracy: 0.8864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTFmlTgMUy6-",
        "outputId": "31fee337-b94d-447a-93d4-62126b5f95ed"
      },
      "source": [
        "print(\"gctf not used\")\r\n",
        "print(f\"Execution time: {sum(time_callback_no_gctf.times)} s\")\r\n",
        "print(f\"Accuracy: {history_no_gctf.history['accuracy'][-1]}\")\r\n",
        "print(f\"Loss: {history_no_gctf.history['loss'][-1]}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gctf not used\n",
            "Execution time: 20.81371283531189 s\n",
            "Accuracy: 0.8871999979019165\n",
            "Loss: 0.30977925658226013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qW351shXgM"
      },
      "source": [
        "## Train a model with `gctf`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slHbE9hKWBWV",
        "outputId": "e4fa0cb7-dbe8-4967-a3d3-523169c40c66"
      },
      "source": [
        "time_callback_gctf = TimeHistory()\r\n",
        "\r\n",
        "model.compile(optimizer = gctf.optimizers.adam(),\r\n",
        "              loss = 'sparse_categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "history_gctf = model.fit(training_images, training_labels, epochs=5, callbacks=[time_callback_gctf])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3085 - accuracy: 0.8899\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2819 - accuracy: 0.8962\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2700 - accuracy: 0.9011\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2599 - accuracy: 0.9017\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2532 - accuracy: 0.9060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k3ah7_mWzbK",
        "outputId": "297afcaa-9286-4d0e-d647-b54f3f5d13ae"
      },
      "source": [
        "print(\"gctf used\")\r\n",
        "print(f\"Execution time: {sum(time_callback_gctf.times)} s\")\r\n",
        "print(f\"Accuracy: {history_gctf.history['accuracy'][-1]}\")\r\n",
        "print(f\"Loss: {history_gctf.history['loss'][-1]}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gctf used\n",
            "Execution time: 19.401079177856445 s\n",
            "Accuracy: 0.9035999774932861\n",
            "Loss: 0.2570233643054962\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}